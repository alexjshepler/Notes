{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Machine Learning?\n",
    "\n",
    "## Traditional Software Development:\n",
    "The input and the algorithm is known, and you write a function to produce an output\n",
    "- Input data\n",
    "- Apply logic to it\n",
    "- Which produces a result\n",
    "\n",
    "## Machine Learning\n",
    "You know the input and the output, but you don't know the algorithm that creates the output given then input\n",
    "- Take pairs of input and output data\n",
    "- Figure out the algorithm\n",
    "\n",
    "When training a neural network, the variables are never changed, only the weights and biases are. For example, converting celsius to fahrenheit the variable would be multiplication and addition and you would multiply the input by some number (the weight) and add another number (the bias). Training involves testing different correlated inputs and outputs and the weight and bias will be changed to fit to match the input and the output.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab: Converting Celsius to Fahrenheit\n",
    "\n",
    "The standard formula for converting celsius to fahrenheit is:\n",
    "\n",
    "> F = C * 1.8 + 32\n",
    "\n",
    "To train a network, instead of giving it the formula, we will feed it 5 corresponding inputs and outputs (for this example)\n",
    "\n",
    "To setup and train the network, make a python file and import tensorflow and numpy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will be doing supervised machine learning because we are trying to figure out an algorithm given a set of inputs and outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celsius_q    = np.array([-40, -10,  0,  8, 15, 22,  38], dtype=float)\n",
    "fahrenheit_a = np.array([-40,  14, 32, 46, 59, 72, 100], dtype=float)\n",
    "\n",
    "for i, c in enumerate(celsius_q):\n",
    "    print(f'{c}\\t degrees celsius = {fahrenheit_a[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Terminology for machine learning:\n",
    "**Feature** - Input to our model  \n",
    "**Label** - Output the model predicts  \n",
    "**Example** - A pair of input and output that the model uses for training\n",
    "\n",
    "For this example we will use a dense network because it is a simple example and a dense network is the most simple\n",
    "\n",
    "When building a layer, **l0** in this case, we can instantiate it with **tf.keras.layersDense** and give it these configurations:\n",
    "\n",
    "`input_shape[1]` - This specifies the input to this layer with a single value  \n",
    "`units` - This specifies the number of neurons per layer. The number of neurons is the number of internal variables that the layer has to learn how to solve. This, for when it is the final layer, also defines the number of outputs. (In a multilayer model the size and shape of the layer needs to match the input_shape of the next layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = tf.keras.layers.Dense(units=1, input_shape=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once the layers are defines, they need to be assembled into a model.\n",
    "\n",
    "A Sequential Model Definition takes a list of layers as an argument, specifying the calculation order from the input to the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([l0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Most of the time the layer will be built and defines inside of the model rather than beforehand.\n",
    "\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, input_shape=[1])\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before a model can get trained, it has to be compiled. When a model gets compiled it is given a loss and optimizer function\n",
    "\n",
    "**`Loss` Function** - A way of measuring the inaccuracy of the model  \n",
    "**`Optimizer` Function** - A way to change the internal values fo increase accuracy and reduce loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.keras.optimizers.Adam(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used for training, because, all training is, is calculate the inaccuracy then adjust to improve.\n",
    "\n",
    "One part fo the optimizing function is the learning rate. This is the step size taken when adjusting values in the model. Too small and it will take too many iterations to be feasible. Too large and the model will be trained too inaccurately.\n",
    "\n",
    "To train the model call the fit function.\n",
    "\n",
    "When training happens, the model takes in the training inputs, celsius, and preforms calculations using the current internal variables, weights. At first the output is going to be random because the weight is randomly set. Then the loss is calculated and the optimizer directs how the weights should be adjusted.\n",
    "\n",
    "The The cycle of calculate, compare, and adjust is controlled by the fit method. The first argument is the inputs, the second is desired outputs, the third is `epochs`, or the amount of times to run the same input through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)\n",
    "print('Finished training the model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit method returns a history object which can be used to see if the history of the loss at the given epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss Magnitude')\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model has ben trained. It can be used to predict outputs given an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict([100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given C * 1.8 + 32 = F where 100 * 1.8 + 32 = 212, our model is doing pretty good\n",
    "\n",
    "### To Review:\n",
    "- We created a model with a Dense Layer\n",
    "- We trained it with 3500 examples (7 pairs, 500 epoches, 1 * 500 = 3500)\n",
    "\n",
    "The model tuned the variables (weights) in the dense layer until it was able to mostly accurately convert celsius to fahrenheit\n",
    "\n",
    "## Recap\n",
    "\n",
    "The training process, what happens in the model.fit(...), is just about adjusting the internal variables of the network to the best values. This is achieved through an optimization process called Gradient Decent, which uses numeric analysis to find the best values\n",
    "\n",
    "Gradient descent works by iteratively adjusting the parameters, nudging them a little at a time to get the best values. It will know when it is at the best value because if it nudges it anymore, it would make the model preform worse.\n",
    "\n",
    "The function that measures the performance is called the loss function.\n",
    "\n",
    "The training process starts with a forward pass. This takes the layer input, applies its internal math on it with the current internal variables,  then predicts the answer. After this, the backpropagation process starts. It first calculates the loss, then the internal variables, the weights and biases, are adjusted in order to minimize the loss. Then the cycle repeats based on the number of inputs and epochs\n",
    "\n",
    "### Terms:\n",
    "*Feature* - The input(s) of our model  \n",
    "*Examples* - The output of our model  \n",
    "*Labels* - The output of our model  \n",
    "*Layer* - A collection of nodes connected together in our neural network  \n",
    "*Model* - The representation of the neural network  \n",
    "*Dense and Fully connected (FC)* - Each node in one layer is connected to each node in the previous layer  \n",
    "*Weights and Biases* - The internal variables in a models neuron  \n",
    "*Loss* - The discrepancy between the desired output and the predicted output  \n",
    "*Mean Squared Error(MSE)* - A type of loss function that counts a small number of large discrepancies as worse than a large number of small ones  \n",
    "*Gradient Descent* - An algorithm that changes the internal variables a bit at a time to gradually reduce the loss function  \n",
    "*Optimizer* - A specific implementation of the gradient descent algorithm  \n",
    "*Learning Rate* - The \"step size\" for loss improvement during a gradient descent  \n",
    "*Batch* - The set of examples used during training  \n",
    "*Epoch* - A full pass over the training set data  \n",
    "*Forward Pass* - The computation of output values from the input  \n",
    "*Backward pass (backpropagation)* - The calculation of internal variable adjustments according to the optimizer algorithm starting form the output layer and working back through each layer to the input\n",
    "\n",
    "## Dense Layers\n",
    "\n",
    "Dense Layers, every node or neuron is connected to every neuron in the pervious layer\n",
    "\n",
    "To make a network that looks like [this](https://viewer.diagrams.net/?tags=%7B%7D&highlight=0000ff&edit=_blank&layers=1&nav=1&title=Untitled%20Diagram.drawio#R7ZpNc5swEIZ%2FjY%2FJIAmIfaRO%2BnHoTDo%2BNOlNBsUwgxGV5YD76ytA4puQOMTATHIJeqVdsdrHWsnjBVrv428Mh%2B5P6hB%2FATUnXqDbBYQALYH4lyinTFlqeibsmOfIQYWw8f4RKWpSPXoOOVQGckp97oVV0aZBQGxe0TBjNKoOe6J%2BddYQ70hD2NjYb6q%2FPYe7MgpDK%2FTvxNu5amagyZ49VoOlcHCxQ6OShO4WaM0o5dnTPl4TP1k8tS6Z3deO3vzFGAn4awxQGDv7P3eWZbu%2FrB94wwwcXUkvz9g%2FyoAX0PSFvy9b8bBLHpTwRMU8Igx%2Bkmtj%2Fj1S1XF1SDNniQFQD%2BPMTPYrRw9AuRIvmXmrziDk0qywMhlk9Bg4JIlFE92R63GyCbGd9EYCPaG5fO%2BLFsitnwnjJO5cLpAnQdBL6J5wdhJDpIEu0ya5RbIZlSCQklvKvyk1LLHb5X6LzIgHmZw3JApeMlFwTomC2rQyhS6ZKTSnTCFzWpnSX8pUS1aa69%2BbyDNMXpt7q%2B9TumVKiZLErKNSfKUugdB629IzJ7Jybk7q3DEyWsYAm0A3O4cQB%2B9jp1yKM29d7LyVVwA75oxACiEQK7Fu4RCkHPYdEeaJJ4ATw9PsxLMTrW4ahy9rVl9ZK3GDUqpQO1Vb9CI4jTdvfBrG3tdqZ5v8VDoWOKCtZtYWiQSOldy8RMv28eHg2dV1qS5ikl557YO6aJPY4w9J37UhW4%2FSLnm%2BjaVZ2jipRiBiy4x0aCjhMRU0hJRQGKetivU9YZ5YIsKkmEVFnMbtsJY6ETk9Mpv037E4ZjvC%2B2pGE4VSqo2WVCuNER9z77n6um35lzPcUy%2F9lObXnSppOqohlIUprcrXzLojo3bIW9YcZevQcJTimIf9DkLbSu%2BUCK3y2cPmgBjCOWC4qhVK7UwKgalXHengerXUij94WSjbCu4nlPlledpQQmMoKm9qjvQL7403H47hhyPVi4o%2BpTK6mispy6mScs5GN0IVHZdCMNCGhdDIGK6mWDcHxKnj%2Bjezuoa6vt%2B4ECZq%2BmlhMoHjlfHK3cocE8Ohzvxjb1Yq8k8Kp1QL6ycpeC5e9d0yb78bL9EsfgaQDS9%2BTIHu%2FgM%3D)\n",
    "\n",
    "You just need to do something like:\n",
    "\n",
    "```python\n",
    "hidden = keras.layers.Dense(units=2, input_shape=[3])\n",
    "output = keras.layers.Dense(units=1)\n",
    "model = tf.keras.Sequential([hidden, output])\n",
    "```\n",
    "\n",
    "The equations for each neuron could look like:\n",
    "\n",
    "a1 = x1 * w11 + x2 * w12 + x3 * w13 + b1\n",
    "a2 = x1 * w21 + x2 * w22 + x3 * w23 + b2\n",
    "a3 = a1 * w31 + a2 * w32 + b3\n",
    "\n",
    "As the training process happens, it will only change the W(eights) and B(iases) variables, not the order or the math.\n",
    "\n",
    "For the conversion example, it looked something like this:\n",
    "\n",
    "[insert conversion diagram]\n",
    "\n",
    "a1 = x1 * w11 + b1\n",
    "\n",
    "This problem isn't realistic for a real world scenario because we know the conversion for celsius to fahrenheit, and if we were to implement it, we would've just hard coded it into a function.\n",
    "\n",
    "In hte real world, it is more of a trial and error solution where the network is given a set of training data, and when it is done training, it gets tested and if the test isn't successful, the number of neurons and layers get changed until it can be accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e25445700cf53fd2672664e39882024c4e86d74e641146a8f32e21781445aee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
